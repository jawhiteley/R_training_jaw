---
title: "A Short Introduction to Working With Data in R"
author: "Jonathan Whiteley"
date: "`r Sys.Date()`"
output: 
  beamer_presentation: 
    latex_engine: xelatex # ensures certain characters (like '^') are rendered correctly
    theme: Boadilla
    colortheme: default
    highlight: ../../shared/my_tango.theme
    slide_level: 2
    toc: false
    keep_tex: no
    includes:
      in_header: "../../shared/preamble-include.tex"
fontsize: 11pt
urlcolor: darkblue   # defined in LaTeX preamble (in_header includes, above)
linkcolor: darkblue  # defined in LaTeX preamble (in_header includes, above)
params:
  is_virtual: TRUE    # is this presentation for a virtual (T) or in-person (F) environment?
knit: 
  (function(input_file, ...) {
    knitr::purl(input_file, documentation = 1);
    render_out <- rmarkdown::render(input_file, ...);
    out_path <- file.path("..", basename(render_out));
    message("Copying output \nfrom '", render_out, "'\n  to '", normalizePath(out_path, mustWork = FALSE), "'" );
    success <- file.copy( render_out, out_path, overwrite = TRUE );
    if (!isFALSE(success)) {
      message("> Output file copied to '", normalizePath(out_path), "'" );
      success <- file.remove( render_out );
      if (!isFALSE(success)) message("> Original file deleted '", render_out, "'");
    };
  })
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment='#')
knitr::opts_knit$set(root.dir = "..")  # run all code as if in the parent directory
options(width = 60)  # to fit output on slides
```

## Prerequisites {.shrink}

-   Access to a copy of the [![](`r file.path(R.home("doc"), "html", "logo.jpg")`){height=1em}](https://www.r-project.org) software
    -   Get it from [*www.r-project.org*](https://www.r-project.org), 
        or ask your system administrator.

- Tidyverse packages installed on the same system as $\R$
  - Please run this command in $\R$ *before* the workshop:
    ```{r install_tidyverse, eval=FALSE}
    install.packages("tidyverse")
    ```

- Download the [workshop files](https://github.com/jawhiteley/R_training_jaw/tree/main/R2_data_scripting), including these slides, data, and scripts.
  - The workshop assumes the same file structure as in the link above.

-   Knowledge of common mathematical operations: arithmetic, logarithms, etc.

-   Knowledge of basic $\R$ concepts, such as *variables*, *objects*, *operators*, *functions*, *packages*, etc.

    -   This is covered in the first workshop: "A Gentle Introduction to R"

::: notes
<!-- R logo: ![](`r file.path(R.home("doc"), "html", "logo.jpg")`){height=1em} -->

- I will use an example data file to demo various cleaning & manipulation steps
- Exercises, however, should generally **stand-alone**
  - Exercises are an opportunity to try to apply knowledge, experiment, sometimes fail, and discuss 
    --- _success_ is not the primary objective.
  - Messing up an exercise should not derail your progress on future exercises.
:::




# Welcome

## Pop Quiz

\annote{\fade{We will review these \textit{at the end}, so you can see how much you have learned.}}

+ If multiple packages have functions with the same name,
  how can you specify which one to use?
+ Does $\R$ store data in memory or temporary files?
+ What is the limit to the size of objects and datasets that can be loaded into $\R$?
+ TRUE or FALSE: $\R$ has rules and conventions for naming functions
+ TRUE or FALSE: if you use one package from the `tidyverse`, you have to use all of them.

```{r welcome, echo=FALSE, results='asis', purl=FALSE}
if (params$is_virtual) {
  cat("\\ 
  \n### Answer in the chat:
  \n
  \nWhat is your favourite emoji?  Why do you like to use it so much?
  ")
}
```


## Introductions

- Name
- Pronouns
- Job title, role
- _optional_: a favourite childhood treat or candy?

<!-- -->

- What are you hoping to learn most in today's workshop?


## Learning Objectives

- Load tabular data into R
- Explore data to check that it was loaded correctly
- Export data from R to external files
- Data frames
- Clean data
  - re-arrange & modify rows
  - Add & change columns
  - Edit values systematically
  - Change data types
- Tidy data
  - Change the _shape_ of a data frame
- Re-use code, reproducible results, automated reports
  - Scripts
  - R Markdown, R Notebooks


## Disclaimer

- There is often more than one way to achieve a desired result in $\R$

- Some are faster in certain situations

- Some require less code, or are easier to write as code

- Some are more portable (work on multiple systems)

- But there is rarely as single 'best way'.

This workshop focuses on a coherent approach,
that can be learned more easily and extended as needed
to tackle bigger problems.

Feel free to take what you learn here
and experiment, or explore alternatives.
Find what works for _you_.




# File Paths and The Working Directory

## The Working Directory

- When working with external files, it helps to know the current _working\ directory_
  - Any paths supplied to $\R$ functions will be relative to this path.

```{r 2.get_working_dir, results='hide'}
getwd()
```

- You can change the working directory with this command:

```r
setwd('path/to/a/directory')
```

## File paths

- A *file path* is a *character string* that represents the location of a file
  in your system (computer and OS)
  
- The format of paths can depend on the operating system (OS)

  - Some use `"/"` to separate directories
    - e.g., "`/dir/subdir`"
    
  - Windows uses `"\"`
    - e.g., `"C:\\dir\subdir"`
    - $\R$ uses this as an escape character in strings, and must be escaped itself in paths (`"\\"`)
    - e.g., `"C:\\\\dir\\subdir"`


## Paths in $\R$

- $\R$ generally uses and understands `"/"` in paths, even on Windows.[^file-paths]

  - e.g.,\ `"C:/dir/subdir"`
  - on Windows, it also understands Windows-style paths: 
    e.g,\ `"C:\\\\dir\\subdir"`

- $\R$ also has platform-independent functions for manipulating paths, 
  such as `file.path()`{.r},
  which I will use in examples to make them as reproducible as possible.

[^file-paths]: For the gory details, see section 14.2 "Filepaths" in "An Introduction to R" (`help.start()`{.r}), `?file.path`{.r}, and documentation for related functions.


## My paths are not like yours

- Directory (folder) names can also vary from one computer to another
  --- it's difficult to show a path in this document that will also work on your computer!

- Once you set a working directory _on your computer_ 
  based on the structure of the files in this project,
  we can use _relative paths_ that should also work on your computer 
  (assuming your downloaded the workshop files in the same structure as provided).


## Set the working directory

- For this workshop, set the working directory to location where you downloaded
  this presentation and accompanying files.
  - the directory that _contains_ the folder named '`data`'
    that you downloaded along with the files for this workshop.

```{r setwd, eval=FALSE, echo=FALSE, results='hide', include=FALSE}
Before running the commands in this file,
set your working directory (*in the console*)
to the folder that *contains* the 'data' folder
(i.e., the workshop folder, as it appears on the web site.)

setwd("path/to/the/folder")
if (.Platform$OS.type == "windows") {
  setwd( choose.dir() )
}
```

:::::: {.columns .onlytextwidth}
::: {.column width="58%"}
* Base $\R$ on Mac / Linux:

  - Menu item: "Misc > Change Working Directory..."
  - `CMD+D` on Mac; `CTL+D` on Linux (or Windows)

:::
::: {.column width="38%"}
* Base $\R$ on Windows:

```r
setwd( choose.dir() )
```

:::
::::::
```{=latex}
\medskip
```
:::::: {.columns .onlytextwidth}
::: {.column width="58%"}

* In RStudio,
  you can use the _Files_ pane (default bottom-right)
  to navigate to a directory in your system,
  and click on "*More > Set As Working Directory*"
  - or "*Session > Set Working Directory > To Files Pane Location*" 
    in the RStudio menu.

:::
::: {.column width="38%"}

![](images/rstudio-set-wd-files.png){width=80%}
:::
::::::

::: notes
  - RStudio also has a menu item to conveniently set the working directory to the same location as a file in the 'Source' pane.  
    We'll use that later with source files.
:::


## Check your working directory

- Check to see that the working directory is in the right place,
  by checking to see if a known file exists (from $\R$'s perspective):

  ```{r check_wd}
  DF_path <- file.path("data", "data_example.csv")
  file.exists(DF_path)
  ```

- If the result of the statement above is not "`TRUE`{.r}" in your session,
  try one of the [other approaches](#set-the-working-directory)
  to change your working directory, and try again.




# Loading Data into $\R$

## csv files

- 'csv' = **C**omma **S**eparated **V**alues
  - files in this format have a '`.csv`' file extension.
  
- They are:
  - plain text files
  - used to represent tabular data, 
    with each *row* on a line, and values in each *column* separated by commas (`,`)
  - readable by a wide variety of analysis software (highly portable)
  - simple---no embedded metadata

- We'll try to load this file into $\R$:  
  `example_data.csv`
  - *optional: you can try opening it in a text editor, or spreadsheet software,
    to see what's in the file.*


## Load a csv file into $\R$ (basic)

```r
?read.csv
read.csv(DF_path)
```
```{r load1, echo=FALSE}
try( read.csv(DF_path) )
```

. . .

- Uh oh!  Something's not right.


## Check the file contents

- Let's take a peek at the first few lines and see if we can identify the problem:
```{r readlines}
readLines(DF_path, n = 4)
```
. . .

- The first **2** lines don't look like comma-separated values!

- They look like extra information that is not part of the data table *structure*.


## Load a csv file into $\R$

- We can tell $\R$ to skip the lines with no data:
  - and we'll *assign* the result to a variable
    so we can work on it
  
```{r load}
DF <- read.csv(DF_path, skip = 2)
```

- Just because there were no `Error`{.r}s from $\R$, 
  doesn't mean there's nothing wrong with the data!




# Exploring Your Data

## Object class: data frame

Before we explore our new data set, let's quickly review the kind of *object* we're dealing with:

```{r 3.data.frame}
class(DF)
typeof(DF)
```

## Data frames

<!--
- Data frames (review)
- head, str, names, plot?
- View / RStudio Environment pane
- Know Your Data
-->

## `head()`: peek at the first few rows

```{r head}
head(DF)
```


## Dimensions (rows & columns)

```{r dims}
dim(DF)
nrow(DF)
ncol(DF)
```

## *Names* of elements (columns)

```{r colnames}
names(DF)
colnames(DF)
rownames(DF)
```

## Look at a column {.shrink}

**Remember:** you can refer to elements within a data frame by *name*.

```{r}
DF[, "Treatment"]
unique(DF$Type)
```

### !

Looks like there might be some missing values in the `Treatment` column, and inconsistencies in the `Type` column.
We'll learn how to fix those soon, 
but these simple functions are already helping us understand our data.

## `str()`: structure of an object

```{r str}
str(DF)
```

### Tip
_The `str()`{.r} and `names()`{.r} functions can be used with **any** object._


## `summary()`: statistical summaries by column

```{r summary}
summary(DF)
```

## Simple plots {.shrink}

```{r plot_basic}
plot(DF)
```


## Spreadsheet-like `View()`

``` r
View(DF)
```
- This command opens a data frame in a spreadsheet-like view,
  which can be easier to navigate.

<!-- base R View() screenshot -->

- In RStudio, you can achieve the same thing by clicking
  on an object name in the '*Environment*' pane (default upper-right)
  - The `View()`{.r} pane in RStudio (default upper-left; '*Source*') 
    also allows for sorting and filtering,
    but these do not change the object in your session, only the view.

<!-- RStudio Environment Pane screenshot -->
<!-- RStudio View screenshot -->


## Encoding non-English characters {.shrink}

```{r reproduce windows latin1, include=FALSE, results='hide', purl = FALSE}
## Reproduce Windows encoding (bad)
DF_win <- read.csv(DF_path, skip = 2, encoding = "latin1")
## Extract example of messed up encoding
latin1_ex <- DF_win |>
  dplyr::select(Type) |>
  dplyr::filter( ! Type %in% c("Quebec", "Mississippi") ) |> 
  unlist() |> unique()
```

- If you are running R in Windows, you may notice that 
  some values of the `Type` column look strange:
  
  "**`r latin1_ex`**" instead of "Québec"

- There is nothing wrong with the file 
  --- this indicates a _mismatch_ between 
  the *encoding* used to write the file,
  and what $\R$ used to read it.

- Even though '`.csv`' files are plain text,
  letters (especially non-english characters)
  can be *encoded* in different ways
  to represent them in the computer.
  
- "[`UTF-8`](https://en.wikipedia.org/wiki/UTF-8)" 
  is a character encoding standard designed to handle many non-english characters.

  - The example data file was written in "`UTF-8`"
  - Most OSes and many programs use "`UTF-8`" encoding by default.
  - But *Windows* uses "`latin1`" by default,
    and so does $\R$ (< [4.2.0](https://stat.ethz.ch/pipermail/r-announce/2022/000683.html)) when running in Windows.
  - Starting with [v4.2.0](https://stat.ethz.ch/pipermail/r-announce/2022/000683.html), $\R$ uses "`UTF-8`" as the default encoding on Windows.


## Read a csv file with a different encoding {.shrink}

- You can specify the encoding used in the file 
  with the '`encoding`' argument of `read.csv()`{.r}
  
```{r read.csv() with encoding}
DF <- read.csv(DF_path, skip = 2, encoding = "UTF-8")
```

- If reading a file that was 
  created on a Windows computer and encoded in "`latin1`",
  on a different system (mac, Unix, linux, etc.)
  --- or a recent version of $\R$ (>=4.2) on Windows ---
  you can specify that, too:
  
``` r
read.csv(DF_path, skip = 2, encoding = "latin1")
```

### Microsoft Excel on Windows

Excel in Windows is capable of saving files in `.csv` format with "`UTF-8`" encoding,
but it adds extra contents to the file (a "BOM") 
that makes it difficult to read with `read.csv()`{.r}.  
See the "Extras" document from this workshop for details on how to deal with that.  
_Or use the `readr` package (coming up) and don't worry about it._ :)

::: notes
See ?read.csv, ?Encoding, ?file, and other documentation for details.
:::


## Know Your Data

- These functions are useful for exploring different aspects of a loaded data set

- But they won't tell you if these are _correct_.

- Ideally, you should always "Know Your Data",
  and use these functions to verify that the data was loaded correctly.
  - Are the number of rows and columns what you expected?
  - Are the different columns of the expected type (numeric, character, etc.)?
  - Are the values in the expected range and format?
  - Is anything missing, or different than expected?


## The `CO2` dataset: background

The example data file is based on the `'CO2'` dataset 
available in $\R$ (`?CO2`),
with a few changes added to make things interesting.

From the documentation:

> The CO2 uptake of six plants from Quebec and six plants from Mississippi 
> was measured at several levels of ambient CO2 concentration. 
> Half the plants of each type were chilled overnight before the experiment was conducted.


## Exercise 1: what's wrong with this data?

The original dataset has the following properties (`str(CO2)`{.r}):

- 84 rows and 5 columns

  --------------  ------------------------------------------------
  Column Name     Description
  --------------  ------------------------------------------------
  `Plant`          factor with 12 levels:
                   Qn1, Qn2, ... Mc3, Mc1

  `Type`           factor with 2 levels:
                   "Quebec" and "Mississippi"
  
  `Treatment`      factor with 2 levels:
                   "nonchilled" and "chilled"
  
  `conc`           numeric: ambient carbon dioxide 
                            concentrations (mL/L)

  `uptake`         numeric: carbon dioxide uptake rates 
                            ($\mu$mol/m^2^$\cdot$sec)
  --------------  ------------------------------------------------

### Your turn

Using the functions described in this section, 
can you identify some possible issues and differences
with the data set you loaded?

_**Spoiler alert:** suggested answers on the next slide._


## Exercise 1: what _is_ wrong with this data {.shrink}

- The data we loaded has different dimensions!
  - Values from the `conc` column are shown as *column names*
  - `uptake` values are the values of these columns
  - This isn't necessarily _bad_:
    such a structure can be useful for presentation
    and interpretation by people,
    but it is not _tidy_ and less convenient 
    for analysis & visualization (more on this later).

- Some of the `uptake` values are *character*,
  but should be *numeric*

- One of the `Type` values is spelled inconsistently:
  "Quebec"/"Québec"
  
- Some values in the `Treatment` column are empty
  - The value is only included when it changes
  
- The `PlantNum` column does not contain a unique identifier,
  as in the original `Plant` column
  - The values are no longer _unique_,
    without also considering the `Type` and `Treatment` columns.
  
_There are other differences you may have noticed:
 we'll look at ways to identify these automatically later._




# Re-using your code: scripts and other files

<!--
√ What is a script? Why use a script?
  √ Make a simple script that does what we've done so far?
√ The comment character '#'
- never use setwd() in a script!
√ > Point to script file of all the code in this workshop to follow along from here onward.
+ Housekeeping: `rm(list=ls())`
+ Flow-control
  - if () else
    - message(), warning(), stop()
  - for () loop
    - apply() functions
+ defining your own functions
  - variable scope, environments?
  - anonymous functions? (*introduce when it becomes relevant*, later)
  * write a custom function for comparing values in two vectors with NAs
    - http://www.cookbook-r.com/Manipulating_data/Comparing_vectors_or_factors_with_NA/
    - https://stackoverflow.com/questions/37610056/how-to-treat-nas-like-values-when-comparing-elementwise-in-r
√ Style Guides
  - https://style.tidyverse.org/syntax.html
  - https://google.github.io/styleguide/Rguide.html
+ Rmd, Notebooks? (save for later)
  - Brief mention, demo
- Projects?
-->

## Re-using code

Before we practice cleaning our data, and saving it to use later ...

- Imagine having to repeat the multiple steps to *load*, *clean*, and *save* a dataset.

  - How will you remember which *packages* you had to load?
  - How will you remember _all_ the steps, and their order?
  - What if you need to change _one_ step, but repeat all preceding steps?
  - How can you share your code with others, so that they can check your work, 
    or replicate your results?
  - How will you write out complex operations that require multiple steps,
    repeated operations, or only do things under certain conditions?

- The answer to all of these questions is: a ***script***

_Scripts and related files will also make it easier for you to follow along
with examples as they get more complicated---copy & paste into the console less often!_


## Scripts

An $\R$ *script* is a file that stores $\R$ code in *plain text*

- They have a `.R` file extension
- They are plain text files
  - so any text editor can read & write them
  - they also work well with **v**ersion **c**ontrol **s**ystems,  
    like [`git`](https://git-scm.com/), [GitHub](https://github.com/), and [GitLab](https://about.gitlab.com/))

- All the code in a script can be run in order
  - i.e., a *program*
- They make it easy to re-use code
- Scripts provide a record of the steps in a program or analysis
  - results are more *reproducible*
  - the code is a form of documentation

::: notes
- Most IDEs and text editors will show the text in different colours to distinguish different parts of the code
  - known as "syntax highlighting"
:::


## Make a new script

- In your $\R$ interface (R GUI, RStudio, IDE, etc.),
  open a new R script
    
  ----------------------------------------------------------------------
  Application   Menu item                           Keyboard shortcut 
                                                    (mac shortcut)
  ------------  ----------------------------        --------------------
  **R GUI**     `File > New Document`               `CTL+N` (`CMD+N`)
  
  **RStudio**   `File > New File > R Script`        `Shift+CTL+N` 
                ![](images/RStudio-toolbar-new.png) (`Shift+CMD+N`)
  ----------------------------------------------------------------------

- Save it with a name like "`my_first_script`[**`.R`**]{.underline}"
  - You can save it in the same location as the slides for this workshop
    (i.e., the folder _containing_ the '`data`' folder.)


## Add some code to your script

- Paste in the following code to your script file:

``` r
DF_path <- file.path("data", "data_example.csv")
file.exists(DF_path)

DF <- read.csv(DF_path, skip = 2, encoding = "UTF-8")

colnames(DF)
plot(DF)
```

- and save it.


## Run $\R$ code in scripts

Most IDEs have a shortcut to send portions of $\R$ code (a line or *statement* spanning multiple lines) to an $\R$ session:
  
  - R GUI: `CTL+Return` (mac: `CMD+Return`)
  - RStudio: `CTL+Return` (mac: `CMD+Return`)

You can run _all_ the code in a script in different ways:

- The `source()`{.r} function, with a path to the script file as an argument
  - The code will run in the current session.
  - `?source`{.r}
  - `source("my_script.R")`{.r}
  
- Run $\R$ in "*batch mode*"
  - "*batch mode*" is **not** interactive (no prompt)
  - It is usually invoked from a terminal or other command-line (outside an $\R$ GUI)
  - The code in the script will run in a new session
  - You can capture output in a separate file
  - `?BATCH`{.r}

::: notes
Pause to let people try it out.
We will not be trying Batch Mode---it is mentioned for information only.
:::


## Comments {.shrink}

* The '**`#`{.r}**' character denotes a *comment* in $\R$
  - _Everything on a line_ after a comment character is ignored by $\R$
  - There are no 'multi-line' comments in $\R$

  ``` r
  print("this is R code")  # this is a comment
  ```

+ You can make an entire line a comment by putting a comment character at the beginning.
  - Divide your code into *sections*
    - `Shift+CTL+R` (`Shift+CMD+R`) in RStudio

  ``` r
  # SECTION -----------------------------------------------------------------
  ```
    
  - Create 'comment headers' for your scripts:

``` r
################################################################
### Title
### Project or description
### Author Name           R vX.X.X              YYYY-MM-DD
################################################################
```


## Comments in code

+ You can put a comment beside a line of code  
  (even in the middle of a mult-line statement)

  + $\R$ will ignore the rest of the line,
  and continue reading code on the next line

``` r
DF <-         # short for "data frame"
  read.csv(   # read a csv file
    DF_path,  # path to file
    skip = 2  # skip lines at top of file (not data)
  )
```

+ Use comments to
  - organize your code (divide it into sections)
  - explain the code, where relevant
  - "comment-out" code temporarily,
    to stop it from running without deleting it
    (useful for debugging).
    - `Shift+CTL+C` (`Shift+CMD+C`) comment a line in RStudio
  <!-- - We'll learn how to stop code from running  -->
  <!--   based on conditions later. -->


## Open a script

* All the code shown in the slides for this workshop 
  has been collected in a script file:
  "`R_data_scripting.R`" (in the '`source`' folder)

* Open it to follow along for the rest of the workshop.

  ------------------------------------------------------------------------
  Application   Menu item                             Keyboard shortcut 
                                                      (mac shortcut)
  ------------  ----------------------------          --------------------
  **R GUI**     `File > Open Document...`             `CTL+O` (`CMD+O`)
  
  **RStudio**   `File > Open File...`                 `CTL+O` (`CMD+O`)
                ![](images/RStudio-toolbar-open.png)
  ------------------------------------------------------------------------


## Set the Working Directory to source file location in **RStudio**

- Menu item: 
  "`Session > Set Working Directory > To Source File Location`"

- This makes it easy to use _relative paths_ in your script,
  relative to the location of the script file itself.
  
### For this workshop
  - All the code in this document
  assumes that the working directory
  is the _parent directory_ of where this file is.

  - After running the menu item above to set the working directory, 
    run this code in your console:
  ``` r
  setwd("..")  # move to the parent directory
  getwd()      # check the current working directory
  ```
  
  - The code in the script should now run without errors.



# The `tidyverse` collection of packages

## The `tidyverse`

``` r
install.packages("tidyverse")
help(package="tidyverse")
```

- The [`tidyverse`](https://www.tidyverse.org/) is an "opinionated" [collection of packages](https://www.tidyverse.org/packages/) that are designed to work together.

- All packages share an underlying design philosophy, grammar, and data structures.
  - _Unlike base $\R$_ <!-- and some other packages -->
  - Shared naming conventions (e.g., '`_`' instead of '`.`' in function names)
  - Emphasis on functions that do one thing well
  - Designed to be combined together to achieve complex operations

- `tidyverse` is under active development.
  - New functions and features sometimes replace or supersede old ones.
  - No guarantee that functions will continue to work the same way in future versions.

::: notes
These characteristics means tidyverse packages may not be ideal in a production environment.
Nevertheless, the package designers are pretty good about replacing old functions with new ones, to avoid disruptive changes, and keeping older functions around, though with only minimal support.
I have code from 10+ years ago that will not run in current versions of R because of the number of changes to dplyr and related packages over the years.

But I still like dplyr and the tidyverse, because they are coherent with each other.
Although they can be complex, and take advantage of some arcane aspects of R,
they do make it easier to translate ideas into code --- once you understand the grammar.
The consistency in naming and argument syntax, however, is also hugely appealing in terms of fewer new things to learn while expanding your toolbox.

Write code that works and that you understand: then take time to revise and optimize, based on your needs and capacity.
:::


## Core `tidyverse` packages

Today, we will focus on a few of the core `tidyverse` packages for loading, cleaning, and manipulating data:

* [readr](https://readr.tidyverse.org/), [readxl](https://readxl.tidyverse.org/) for **loading** data
<!-- * [tibble](https://tibble.tidyverse.org/) for a 'modern' version of `data.frame`s that behave slightly differently (but are compatible with `data.frame`s). -->
* [dplyr](https://dplyr.tidyverse.org/) for **manipulating** data (values)
* [tidyr](https://tidyr.tidyverse.org/) for **reshaping** data
* [stringr](https://stringr.tidyverse.org/) for working with **strings**




# Load Data: The `readr` & `readxl` Packages

<!--
√ read_csv()
  √ compare results with read.csv()
  √ Exercise: use known functions to identify differences in a separate script file?
  - options for controlling behaviour (column classes, NAs)
√ read_excel() example (short, built-in)
-->

## The `readr` package: reading data

+--------------------+-----------------------------+--------------------+-----------------------+
| **`readr`**                                      | **`base R`**                               |
+====================+=============================+====================+=======================+
| `read_csv()`{.r}   | comma separated values      | `read.csv()`{.r}   |                       |
+--------------------+-----------------------------+--------------------+-----------------------+
| `read_csv2()`{.r}  | '`;`' as delimiter\         | `read.csv2()`{.r}  | '`,`' for decimals,\  |
|                    | (allows '`,`' for decimals) |                    | '`;`' as separator    |
+--------------------+-----------------------------+--------------------+-----------------------+
| `read_tsv()`{.r}   | tab separated values        | `read.delim()`{.r} | delimited files       |
|                    |                             |                    | (tab is default)      |
+--------------------+-----------------------------+--------------------+-----------------------+
| `read_delim()`{.r} | (generic) files             | `read.table()`{.r} |                       |
|                    | with any delimiter          |                    |                       |
+--------------------+-----------------------------+--------------------+-----------------------+
| `read_fwf()`{.r}   | fixed width files           | `read.fwf()`{.r}   |                       |
+--------------------+-----------------------------+--------------------+-----------------------+

`readr` descriptions based on [#dsbox](https://datasciencebox.org/course-materials/_slides/u2-d12-data-import/u2-d12-data-import#5)


## Read a csv file using `read_csv()`

- In keeping with Tidyverse conventions, functions are names with words separated by "`_`" 
  - instead of "`.`" or `camelCase`, as in many base $\R$ functions

```{r read_csv}
library(readr)
DF_readr <- read_csv(DF_path, skip = 2)
```


## Exercise 2: compare results from `read.csv()` and `read_csv()`

- Use the functions we [learned earlier](#head-peek-at-the-first-few-rows) 
  to inspect and compare the results of 
  `read.csv()` (in base $\R$) and 
  `read_csv()` (from the `readr` package)

- There's a script file in the `exercises` folder to get you started.

  - "`R2_exercise_2.R`"

### **Spoiler alert:**

_suggested answers on the next slide._


## Exercise 2: comparison of `read.csv()` and `read_csv()`

- The column names are different
  - `read.csv()`{.r} automatically applies `make.names()`{.r} to the column names 
    to make 'syntactically valid' names to use in $\R$.
  - convenient, but not always what we want.
  - there are other 'cleaning' functions available 
    (e.g.,\ `clean_names()`{.r} in the [`janitor` package](https://cran.r-project.org/web/packages/janitor/vignettes/janitor.html))

- `read_csv()`{.r} automatically replaced empty strings 
  in the `Treatment` column with `NA`{.r}s.

- `read_csv()`{.r} left the '`675`' column as numeric,
  but ignored the commas, resulting in larger numbers.

- `read_csv()`{.r} produces a `tbl_df` (*tibble*) object,
  not a simple `data.frame`


## Tibbles: `data.frame`s reimagined

* A ['tibble'](https://tibble.tidyverse.org/) (`class()`{.r} = `tbl_df`) is 
  "a modern reimagining of the data.frame".
  - See the [package documentation](https://tibble.tidyverse.org/) for details.

+ Many tidyverse functions produce tibbles by default.

+ **Tibbles are _also_ `data.frame`s**, and *inherit* from that class.
  - functions that work with `data.frame`s should also work with tibbles.
  - but some may behave differently (by design).
  - for example, `print()`ing a tibble includes slightly more information,
    and only prints a few rows and columns by default,
    preventing large datasets from overwhelming your console.
  - when indexing a tibble, it will _not_ do partial matching on column names,
    making it clear if a column exists or not

+ For most purposes, tibbles are interchangeable with `data.frame`s.
  - A tibble can be converted to a 'plain' `data.frame` 
    with `as.data.frame()`{.r} if necessary.


## Tibble examples

```{r tibble examples}
print(DF_readr, n=2)
is.null(DF$Treat)
is.null(DF_readr$Treat)
```


## `read_csv()`: column names

- The default for `read_csv()`{.r} is to 
  ensure all column names are _unique_,
  but not necessarily *syntactically valid*

- You can still refer to columns with syntactically 'invalid' names:
  - use functions that allow names as characters,
  - quote names with backticks (``` ` ```{.r})

```{r names with backticks, results='hide'}
DF_readr[, "95"]  # still a `data.frame` (with 1 column)
DF_readr[["95"]]  # vector
DF_readr$`95`     # quoted name
```

  
## `read_csv()`: treat column names

- Change how `read_csv()`{.r} treats column names
  with the '`name_repair`' argument

```{r read_csv() name_repair, results='hide', message=FALSE}
read_csv(
  DF_path, skip = 2, 
  name_repair = "universal" # make names unique and syntactic
)

read_csv(
  DF_path, skip = 2, 
  name_repair = make.names  # a function: same as read.csv()
)  
```


## `read_csv()`: guessing column types

- By default, `read_csv()`{.r} prints a message summarizing what it did,
  including _guessing the data type_ of each column.
  
  - _`.csv` files do not include this information as metadata_

- Control how columns are guessed with the `guess_max` argument:

```{r read_csv() guess examples, results = 'hide', message=FALSE}
# use the first 2 rows to guess column types (less successful)
  read_csv(DF_path, skip = 2, guess_max = 2)
# use *all* rows to guess column types
# - slow: has to read *every row* twice.
  read_csv(DF_path, skip = 2, guess_max = Inf)
```


## `read_csv()`: specify column types

- If you know what the column types are (or should be),
  you can tell `read_csv()`{.r} what they are
  with the `col_types` argument.
  - for large datasets, this can be faster: read rows once
  - avoid bad guesses.
  
```{r read_csv() column spec, results = 'hide', message=FALSE, warning=FALSE}
## Specify column types with a compact string
read_csv(DF_path, skip = 2, col_types = "cccddddddd")

## Or use a `column specification`
# extract specification from tibble
col_spec <- spec(DF_readr)
# change a column to numeric (double)
col_spec$cols[["500"]] <- col_double()
read_csv(DF_path, skip = 2, col_types = col_spec)

# ?read_csv for more options
```

## `read_csv()`: all columns as strings

- In extreme cases, you can read everything as '`character`',  
  then clean and coerce to other data types within $\R$

```{r read_csv() all columns as character}
# read all columns as character
read_csv(DF_path, skip = 2, 
         col_types = cols(.default = col_character())
         )
```


## `read_csv()`: missing values

- Use the `na` argument to supply a list of values
  to replace with `NA`{.r}.
  - This is applied to **all** columns.

```{r read_csv() na argument, message=FALSE, warning=FALSE}
read_csv(DF_path, skip = 2, 
         na = c(".", "NA")  # will not replace empty strings ("") with NA
         )
```

::: notes
The example actually produces a warning:
The missing values in lines 12 & 13 (including header row)
are read as an empty character string (""),
then dropped when coerced to numeric,
triggering the usual warning.
:::


## The `readxl` package

Provides functions for reading from (but not writing to) Microsoft\ Excel files (`.xls` and `.xlsx`)

```{r readxl demo}
library(readxl)    # load the package
## Documentation: ?read_excel  help(package="readxl")
## use an example included in the package
xl_path <- readxl_example("datasets.xlsx")
excel_sheets(xl_path)  # get the names of the sheets
## read a specified sheet from the Excel file
iris_xl <- read_excel(xl_path, "iris")
```


## Example 3: read a messy Excel file

- `read_excel()`{.r} has many of the same arguments as 
  `read_csv()`{.r} to control how data is imported.

- Use the script file in the "`examples`" folder as a starting point:
  - "`R2_exercise_3.R`"

```r
XL_path <- readxl_example("deaths.xlsx")
XL <- read_excel(XL_path, ...)
```

. . .

### Tip

Use the '`range`' argument to read data from a specific range in a sheet, 
ignoring contents outside this range 
(rows above & below, columns before & after)

::: notes
Skip this exercise if running late.
:::




# Clean Data: The `dplyr` Package

<!--
Use loaded data set for demos; `who` or `iris` data for exercises?
  - I would like participants to practice using internal datasets for exploration & testing code.
  - I don't want participants to get lost or derailed if they miss an exercise
* ROWS
  + filter() ***
    - package::function notation (to distinguish from other functions named 'filter')
    - near()?
    - duplicates: find, drop [after merging?]
  + sorting: arrange() **
    - pipes
    - group_by()
* COLUMNS
  + select() **
    * tidy-select? ?dplyr_tidy_select
  + rename(), relocate()
  + mutate() ***
  * dplyr semantics (select vs mutate)?
+ summarize() ***
+ Cleaning: editing values systematically
  - ifelse(), if_else() (mutate semantics and variable name scope?)
  - case_when()
  - factors?
* MULTIPLE TABLES
  + combining datasets
    - rbind / bind_rows
    - cbind / bind_cols
    - join() [mention merge()?]
    - Exercise: summarize() a dataset and merge back with original for calculation?
      - or just group_by() & mutate()
* data masking? (advanced) ?args_data_masking
  * {{ var }} and when to use it?
  - https://dplyr.tidyverse.org/articles/programming.html
  - vignette("programming", package = "dplyr")
+ Exercise: stick with multiple tables exercise, above?
-->

## `dplyr`: a grammar of data manipulation

- `dplyr` provides many functions that follow a coherent framework or "_grammar_"
  
- They are intended to help you focus on _what_ you want to do, 
    and translate your thoughts into code.

- High-level functions have active names and called "**verbs**" --- they describe what they do.

- `dplyr` and `tidyselect` provide many "**helper functions**" that work _inside_ verbs 
  and other `tidyverse` functions to make common tasks easier to translate into code.
  - These functions may not work on their own, 
    outside of `dplyr` verbs and `tidyr` functions
    (see `?"faq-selection-context"`{.r}).


## `dplyr` verbs

Verbs can be grouped based on the component of the dataset that they work with[^1-table-verbs]:

- Rows:
  - `filter()`{.r} chooses rows based on column values.
  - `slice()`{.r} chooses rows based on location.
  - `arrange()`{.r} changes the order of the rows.
- Columns:
  - `select()`{.r} changes whether or not a column is included.
  - `rename()`{.r} changes the name of columns.
  - `mutate()`{.r} changes the *values* of columns and creates new columns.
  - `relocate()`{.r} changes the order of the columns.
- Groups of rows:
  - `group_by()`{.r} defines groups of rows.
  - `summarise()`{.r} collapses a group into a single row.
  

[^1-table-verbs]: https://dplyr.tidyverse.org/articles/dplyr.html#single-table-verbs


::: notes

:::


## `dplyr` conventions

All `dplyr` verbs (and other related `tidyverse` functions) share a few things in common:

- The first argument is a data frame (or tibble).

- Other arguments describe what to do with the data frame. 

- You can refer to columns in the data frame directly without using `$`{.r}.

- The result is a new data frame.

We'll see how these can help build clear and efficient workflows.

Because all the functions have these in common, 
it makes it easier to extend your understanding to new functions.

<!-- https://dplyr.tidyverse.org/articles/dplyr.html#commonalities -->




## `dplyr` *semantics*

`dplyr` verbs and helper functions let you refer to column names
of the data frame directly in their arguments 
as regular variables --- without having to quote them as strings.
But these names have different meanings (semantics) in different verbs.

* **"select semantics"**: in `select()`{.r} and similar functions, 
  a column name refers to its _position_ in the data frame.
  - you can refer to a column as a quoted string in `select()`{.r},
    and it is interpreted as a reference to the column.

* **"mutate semantics"**: in `mutate()`{.r},
  a column name refers to a _vector of values_.
  - you cannot supply a column name as a string in `mutate()`{.r},
    because it is treated as a vector of length 1, 
    rather than a reference to a column of values.

::: notes
https://dplyr.tidyverse.org/articles/dplyr.html#patterns-of-operations
`vignette("dplyr")`{.r}
:::





## A 'pipe' operator  {.shrink}

:::::: {.columns .onlytextwidth align=center}
::: {.column width="38%"}

![["La Trahison des Images" ("The Treachery of Images")](https://en.wikipedia.org/wiki/The_Treachery_of_Images) or "Ceci\ n'est pas une pipe" ("This\ is not a pipe") by René Magritte. 
<!-- [Image from Wikipedia](https://en.wikipedia.org/wiki/The_Treachery_of_Images#/media/File:MagrittePipe.jpg). -->
](images/MagrittePipe.jpg)

\centering

[![`magrittr` logo.](images/magrittr_logo.png){height=25%}](https://magrittr.tidyverse.org/)

:::
::: {.column width="58%"}

- The [`magrittr`](https://magrittr.tidyverse.org/) [package](https://cran.r-project.org/package=magrittr) (included with [`tidyverse`](https://www.tidyverse.org/packages/#program)) provides a "forward-pipe operator"<!--[^not-a-pipe]-->:

  ``` r
  %>%    # ?magrittr::`%>%`
  ```

- The `magrittr` package is automatically loaded when loading most `tidyverse` packages (e.g., `tidyr`, `dplyr`, `ggplot2`).
  
  - These packages were designed to work with this operator, and use it themselves.

  - It is often unnecessary to load `magrittr` separately, unless you are **not** using these other packages.

:::
::::::

<!-- [^not-a-pipe]: Although it is a 'pipe' operator, it does not contain a 'pipe' character (`|`), hence the reference to René Magritte's surrealist painting. -->

::: notes
`magrittr` logo downloaded from: https://github.com/tidyverse/magrittr/blob/main/man/figures/logo.png
:::


## `magrittr`'s 'forward-pipe' operator

- `%>%`{.r} allows you to pass results from an expression on the left-hand side (LHS) as an argument (usually the first) to a *function call* on the right-hand side (RHS).  

+--------------------------------+--------------------------------+
| This expression ...            | is equivalent to:              |
+================================+================================+
| ``` r                          | ``` r                          |
| x %>% f()                      | f(x)                           |
| ```                            | ```                            |
+--------------------------------+--------------------------------+
| ``` r                          | ``` r                          |
| x %>% f(y)                     | f(x, y)                        |
| ```                            | ```                            |
+--------------------------------+--------------------------------+
| ``` r                          | ``` r                          |
| x %>% f(y, z = .)              | f(y, z = x)                    |
| ```                            | ```                            |
+--------------------------------+--------------------------------+
| ``` r                          | ``` r                          |
| x %>% f %>% g %>% h            | h(g(f(x)))                     |
| ```                            | ```                            |
+--------------------------------+--------------------------------+

- This can make code easier to read, as expressions are written and evaluated from _left to right_, rather than from _inside to outside_ nested parentheses.


## $\R$ now has a 'native' pipe operator

- A pipe operator was introduced in base $\R$ in v4.1 (May 2021)[^R4.1]:

  ``` r
  |>    # ?pipeOp
  ```

- It was inspired by the "forward pipe operator" introduced by `magrittr`, but is more streamlined. 
  See these links for details:

  - [Differences between the base R and magrittr pipes](https://www.tidyverse.org/blog/2023/04/base-vs-magrittr-pipe/)
  - "[Understanding the native R pipe |>](https://towardsdatascience.com/understanding-the-native-r-pipe-98dea6d8b61b)"

- Because it is so new, most code examples online still use '`%>%`{.r}' from `magrittr`.  

- But '`|>`{.r}' is always available *in $\R$ >= v4.1*, 
  without having to load additional packages.
  
- This document will use '`%>%`{.r}' in the examples, 
  for consistency and because many `tidyverse` functions
  were designed to work with it.


[^R4.1]: https://cran.r-project.org/bin/windows/base/old/4.1.0/NEWS.R-4.1.0.html


## Define your own function

```{r user-defined function, echo=-(1:2)}
# http://www.cookbook-r.com/Manipulating_data/Comparing_vectors_or_factors_with_NA/
# https://github.com/jawhiteley/R-lib/blob/master/functions/compare-na.R
`%==%` <- function (v1, v2) {
  same <- (v1 == v2) | (is.na(v1) & is.na(v2))
  same[is.na(same)] <- FALSE
  return(same)
}

# test it:
c(1, NA, 3, 4 , NaN) %==%
c(1, NA, 1, NA, NaN)
```





# Reshape Data: The `tidyr` Package

## Tidy data

> > "Happy families are all alike; every unhappy family is unhappy in its own way."  
> > — Leo Tolstoy 
  \
  \
> "Tidy datasets are all alike but every messy dataset is messy in its own way."  
> --- Hadley Wickham (doi: [10.18637/jss.v059.i10](https://doi.org/10.18637/jss.v059.i10))


- Tidy datasets provide a standardized way 
  to link the *structure* of a dataset (its physical layout) with its *semantics* (its meaning).

* A [tidy dataset](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) 
  follows three interrelated rules:

  * Each variable must have its own column.
  * Each observation must have its own row.
  * Each value must have its own cell.


## The `tidyr` package

The `tidyr` package provides tools for making data *tidy*:

  + "**[Pivoting](https://tidyr.tidyverse.org/articles/pivot.html)**" 
    converts between *long* and *wide* forms.
    - `pivot_longer()`{.r} and `pivot_wider()`{.r}
  
  + "[Rectangling](https://tidyr.tidyverse.org/articles/rectangle.html)" 
    turns deeply nested lists (e.g., JSON) into tidy tibbles.
    - _Not covered here: see the [vignette](https://tidyr.tidyverse.org/articles/rectangle.html)._
  
  + "[Nesting](https://tidyr.tidyverse.org/articles/nest.html)"
    converts grouped data into nested data frames.
    - _Not covered here: see the [vignette](https://tidyr.tidyverse.org/articles/nest.html)._
  
  + **Splitting** and **combining** character columns.
    - `separate_...()`{.r} a single character column into multiple columns
    - `unite()`{.r} multiple columns into a single character column.
    
  + Handling **missing values**
    - make implicit missing values explicit with `complete()`{.r}
    - make explicit missing values implicit with `drop_na()`{.r}
    - replace missing values with a known value using `replace_na()`{.r}  
      or `fill()`{.r} them with the next/previous value




# Saving Data Outside $\R$

<!--
- write_csv
- file encoding: accents (french)
  - writing & reading
- .Rdata files?  ?save  ?load
-->

## The `readr` package: writing data

+--------------------------+----------------------------------+------------------------+
| **`readr`**                                                 | **`base R`**           |
+==========================+==================================+========================+
| `write_csv()`{.r}        | &larr; comma separated values    | `write.csv()`{.r}      |
+--------------------------+----------------------------------+------------------------+
| `write_csv2()`{.r}       | &larr; allows '`;`' as delimiter | `write.csv2()`{.r}\    |
|                          | and '`,`' for decimals           | '`,`' for decimals,\   |
|                          | (depending on locale)            | '`;`' as separator     |
+--------------------------+----------------------------------+------------------------+
| `write_tsv()`{.r}        | &larr; tab separated values      |                        |
|                          |                                  |                        |
+--------------------------+----------------------------------+------------------------+
| `write_delim()`{.r}      | &larr; (generic) files           | `write.table()`{.r}    |
|                          | with an arbitrary delimiter      |                        |
+--------------------------+----------------------------------+------------------------+
| `write_excel_csv()`{.r}, | &larr; include a UTF-8           |                        |
| `write_excel_cs2v()`{.r} | Byte order mark, which           |                        |
|                          | indicates to Excel the csv       |                        |
|                          | is UTF-8 encoded                 |                        |
+--------------------------+----------------------------------+------------------------+

## Save our work

- Save a data frame to a `.csv` file:
  - it will be encoded with `UTF-8` by default (on all platforms)
  
```{r write_csv, eval=FALSE}
write_csv(DF_tidy, "data/data_clean.csv")
write_excel_csv(DF_tidy, "data/data_excel.csv")
```

- Read it back in to check
```{r test write, eval=FALSE}
save_test <- read_csv("data/data_clean.csv")
save_test
```

```{r cleanup, include=FALSE, purl=FALSE, eval=FALSE}
file.remove("data/data_clean.csv")
```




# Sharing Code & Results

## Style

> "L'enfer, c'est les autres" ("Hell is other people")  
> --- Jean-Paul Sartre ("Huis clos" / "No Exit")
\
\
> "Hell is other people's code."
> --- programming aphorism

- The syntax of the $\R$ language is strict about some things,
  but not others, like white space and indentation.

- As mentioned at the beginning, there is often more than one way
  to do things in $\R$
  - different styles of _naming things_
  - different name formats: `camelCase`, `snake_case`, etc.

- Reading someone else's code that is written in a different style,
  or with inconsistent formatting,
  can be confusing.

## Style Guides

- A "Style Guide" can be a useful tool to help
  you and your collaborators write code
  in a consistent style.

- It also simplifies writing code,
  by reducing the number of (style) decisions
  you have to make.

- A Style Guide is ***strongly** recommended*
  for teams collaborating on shared code.
  
  - Even if you are working alone,
    it can help you write cleaner code
    that's easy for your _future-self_ to read and understand,
    and for others to help you when you get stuck.

### Some popular R style guides you can use (or adapt):

  - [The tidyverse style guide](https://style.tidyverse.org/syntax.html)
    - based on an earlier version of Google's style guide.
  - [Google's R Style Guide](https://google.github.io/styleguide/Rguide.html)
    - based on the current tidyverse style guide, above.




# Review

## Exercise

<!--
in pairs, or small groups:
write a script (or two companion scripts) that
- load a series of files in a folder (portions of `who`?)
  - ue existing dataset, split up by a grouping variable (or year, etc.)
- cleans each one to be consistent (in a function)
- combine them into a single dataset
- re-arrange (pivot) the final dataset
- compare to reference file to test success?
  - have another team / person write a script to do this?
- export & save the file

e.g.:
who2_mod <- 
  who2 %>% 
  filter(country %in% c("Canada", "United States of America")) %>% 
  rowwise() %>% 
  mutate(cases = sum(c_across(sp_m_014:rel_f_65), na.rm = TRUE)) %>% 
  select(country, year, cases)


One option is to have one person or group introduce some 'errors'
and have another try to fix them, but it's easy to introduce
very difficult issues to solve, so this can be risky and time-consuming.
Might work best with a few parameters to limit the kinds of changes that can be made.
-->


## [Quiz](#pop-quiz) Review

<!-- copy questions from [Pop Quiz][], above. -->


::: notes
`## Answers (for discussion)`

:::




# Backmatter

## Other packages to look at

- [`data.table`](https://rdatatable.gitlab.io/data.table/): a high-performance version of `data.frame` with few dependencies.

Other packages in the `tidyverse`:

- [`lubridate`](https://lubridate.tidyverse.org/) and [`hms`](https://hms.tidyverse.org/): for date & time values.

- [`purrr`](https://purrr.tidyverse.org/): functional programming (FP) tools for working with functions and vectors.  
  - Replace `for` loops with code that is more efficient and easier to read.




## References

Cheatsheets:

- [readr/readxl](https://rstudio.github.io/cheatsheets/html/data-import.html)
- [Data transformation with dplyr](https://rstudio.github.io/cheatsheets/html/data-transformation.html)
- [Data tidying with tidyr](https://rstudio.github.io/cheatsheets/html/tidyr.html)

On the web:

- [Tidyverse documentation](https://tidyverse.tidyverse.org/)
- [R for Data Science](https://r4ds.hadley.nz/data-transform.html) (2e)
- [Data Science in a Box](https://datasciencebox.org/) (#dsbox)
- [An introduction to data cleaning with R](https://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf)

$\R$ Documentation:

- "[R Data Import/Export](https://cran.r-project.org/doc/manuals/r-release/R-data.html)" 
  (`help.start()`{.r}, under "Manuals")

::: notes
https://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf
https://r4ds.hadley.nz/data-transform.html (https://r4ds.had.co.nz/transform.html)
  https://github.com/rstudio-education/r4ds-instructors
  https://dplyr.tidyverse.org/articles/dplyr.html#single-table-verbs
  https://dplyr.tidyverse.org/articles/two-table.html
https://education.rstudio.com/teach/materials/
  https://github.com/rstudio-education/remaster-the-tidyverse/blob/master/README.md
  https://datasciencebox.org/
  https://rladiessydney.org/courses/ryouwithme/02-cleanitup-0/
https://posit.cloud/learn/primers

CANSIM data:
https://mountainmath.ca/canssi/#1
https://mountainmath.github.io/canadian_data/

Working directory & scripts:
https://stackoverflow.com/questions/3452086/getting-path-of-an-r-script
https://stackoverflow.com/questions/47044068/get-the-path-of-current-script
https://cran.r-project.org/web/packages/this.path/this.path.pdf
https://github.com/yihui/knitr/issues/332#issuecomment-74100107
  - causes 'duplicate label' errors :(

Other related tutorials:
https://posit.co/resources/videos/a-gentle-introduction-to-tidy-statistics-in-r/

CSV files & encoding:
https://stackoverflow.com/questions/16838613/cannot-read-unicode-csv-into-r
https://donnees-data.tpsgc-pwgsc.gc.ca/dd/csv_df-eng.html#multiline
  - Found this in a Google search, but not sure how current or 'official' it is.
:::
