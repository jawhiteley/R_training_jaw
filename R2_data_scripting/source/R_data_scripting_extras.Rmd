---
title: "A Short Introduction to Working With Data in R"
subtitle: 'EXTRAS'
author: "Jonathan Whiteley"
date: "`r Sys.Date()`"
output: 
  beamer_presentation: 
    latex_engine: xelatex # ensures certain characters (like '^') are rendered correctly
    theme: Boadilla
    colortheme: default
    highlight: ../../shared/my_tango.theme
    slide_level: 2
    toc: true
    includes:
      in_header: "../../shared/preamble-include.tex"
fontsize: 11pt
urlcolor: darkblue   # defined in LaTeX preamble (in_header includes, above)
linkcolor: darkblue  # defined in LaTeX preamble (in_header includes, above)
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "..") })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment='#')
options(width = 60)  # to fit output on slides
```

# Downloading Data From the Internet

```{=html}
<!--
- You can use read.csv & read_csv on urls directly!
  - the same example file, directly from the URL on GitHub
- downloading data from the internet (to a temp dir)
  - the same example file, directly from the URL on GitHub
  - download.file()
- CANSIM / NDMr / other package?
-->
```

# File Encoding & Microsoft Excel^TM^

- Many OSes and applications encode text using "`UTF-8`" by default.
- Windows uses "`latin1`" encoding by default.
- Excel can save a `.csv` file using `UTF-8` encoding,
  but in doing so, it adds "[**b**yte **o**rder **m**ark](https://en.wikipedia.org/wiki/Byte_order_mark)" ("BOM")
  to the file.
  - This is a special character that Excel also uses to recognize
    that the file is encoded using `UTF-8`.
  - Thus a BOM can make the file "easier" to use with Excel,
    by allowing it to automatically recognize the `UTF-8` encoding,
    but it can also **cause problems for other programs** (like $\R$) 
    that do not expect such a non-Unicode character.
  
- Without the BOM, Excel will assume the file is encoded in "`latin1`"
  if you double-click on the csv file to open it in Excel,
  even if it was actually encoded with `UTF-8`.
  - This can cause special characters to appear incorrectly.
  - You can still import a `.csv` file encoded in `UTF-8`
    into Excel correctly, but it requires opening the file within Excel,
    or [importing it using commands in the "Data" ribbon / menu](https://stackoverflow.com/questions/6002256/is-it-possible-to-force-excel-recognize-utf-8-csv-files-automatically)


## Read a file with a BOM using `read.csv()`

- Reading a `.csv` file with a BOM using the usual method 
  may cause [the BOM to be included in the name of the first column](https://stackoverflow.com/questions/39593637/dealing-with-byte-order-mark-bom-in-r)
  (on Windows).
  
```{r read.csv() BOM, results='hide'}
bom_bad <- read.csv("../data/data_example_bom.csv", 
                    encoding = "UTF-8")
names(bom_bad)
```

- The solution with `read.csv()`{.r} is to use the argument  
  '`fileEncoding = "UTF-8-BOM"`' 
  (instead of the '`encoding`' argument)
  
```{r read.csv() BOM fileEncoding}
bom <- read.csv("../data/data_example_bom.csv", 
                fileEncoding = "UTF-8-BOM")
bom[4, 1:4]
```

::: notes
?read.csv
* encoding = specifies how the text in the input file is encoded
  - it is *not* used to re-encode the input, but to handle it in its native encoding
* fileEncoding = tells R the encoding used in the file; 
  - R will re-encode it into the native encoding.
- i.e., `fileEncoding = "UTF-8-BOM" tells R to re-encode the input from UTF-8 (and drop the BOM)
  - `encoding` alone might not drop the BOM, because there is no re-encoding.
:::


## Read a file with a BOM using `read_csv()` {.shrink}

- The `readr` package uses "`UTF-8`" encoding by default,
  and **automatically ignores a BOM**, if present.

```{r read_csv() BOM, message=FALSE}
bom_readr <- readr::read_csv("../data/data_example_bom.csv")
bom_readr[4, 1:4] |> as.data.frame()
```

- `write_csv()` (in the `readr` package) automatically encodes output files using "UTF-8",
  for greater portability across systems.
  - _except_ for base $\R$ (`read.csv()`) using default options. :(
- You can control the encoding used by `readr` functions with the `locale` argument.
  - see `?readr::read_csv` and `?readr::locale` for details.

### !

Hopefully, these examples have demonstrated that 
using `read_csv()`{.r} avoids many of the pitfalls and frustrations of `read.csv()`

::: notes
Load a file with a BOM 
- https://stackoverflow.com/questions/39593637/dealing-with-byte-order-mark-bom-in-r
- https://github.com/ropensci-archive/gtfsr/issues/19#issuecomment-247766324
- https://github.com/tidyverse/readr/issues/263
- https://github.com/tidyverse/readr/issues/500
- https://stackoverflow.com/questions/18789330/r-on-windows-character-encoding-hell
:::


## Add a BOM to an output file

- Some programs (e.g., Excel) expect a BOM
  in "`UTF-8`" encoded files.

- It is possible to add a BOM to a csv file,
  but it must be done _manually_:
  - code adapted from [this StackOverflow answer](https://stackoverflow.com/a/41408091)
  
```r
writeChar(
  iconv("\ufeff", to = "UTF-8"), 
  "output.csv", 
  eos = NULL
)
write_csv(Data, "output.csv", append = TRUE, ... )
```

**$\R$ does not recommend doing this** (see `?file`),
  so use with caution.

::: notes
Add a BOM to a file
- ?file
- https://stackoverflow.com/a/41408091
:::


# Exporting to other formats

## Writing to Microsoft Excel^TM^ files {.shrink}

Packages that can write to Excel files:

-   [`xlsx`](https://github.com/colearendt/xlsx): read, write, format Excel 2007 (`.xlsx`) and Excel 97/2000/XP/2003 (`.xls`) files.
    -   Depends on Java and the `rJava` package
-   [`XLConnect`](https://github.com/miraisolutions/xlconnect): comprehensive and cross-platform R package for manipulating Microsoft Excel files (`.xlsx` & `.xls`) from within R.
    -   Requires a Java Runtime Environment (JRE)
-   [`openxlsx`](https://ycphs.github.io/openxlsx/index.html): simplified creation of Excel `.xlsx` files (**not** `.xls`).
    -   *No dependency* on Java
-   [`writexl`](https://docs.ropensci.org/writexl/): portable, light-weight data frame to **xlsx** exporter.
    -   No Java or Excel required

### !

I recommend *avoiding* exporting data to Excel files if possible. `csv` files are easier to read to & write from, and can be read by a wider variety of software (they are more portable).  
Automated reports can be produced with R Markdown and output to a variety of more portable formats (pdf, HTML, etc.) instead.

::: notes
As seen here, there are several packages for working with Excel files, with different advantages and disadvantages: you may have to do some testing to find the best fit for your situation.

I personally prefer the `openxlsx` package, because in my experience, the dependency on Java can be difficult to get working and unreliable. But I have no experience with `writexl`, which is newer and possibly faster than the others.\
The main trade-off is the openxlsx cannot write to `.xls` files (Excel 97/2000/XP/2003 format) and has fewer formatting options than other packages --- but if you need that much formatting, why not produce a formatted report with R Markdown?
:::

## References (Extras)

CANSIM / CODR data:

- [An ecosystem of R packages to access and process Canadian data](https://mountainmath.ca/canssi/#1)
- [Analyzing Canadian Demographic and Housing Data](https://mountainmath.github.io/canadian_data/)
